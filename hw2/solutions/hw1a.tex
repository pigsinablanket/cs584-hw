\subsection*{Solution}
\subsubsection*{Pseudocode}
\begin{verbatim}
  jarvisMarch(xs) {
    p = minOfXAxis(xs)
    convexHull = [p]

    forever:
      q = xs[0]
      for i in xs:
        if orientation(p, i, q) is counterclockwise:
           q = i
      p = q
      convexHull = cons(p, convexHull)

      if last(convexHull) == p:
        break

    return convexHull
  }
\end{verbatim}

\subsubsection*{Description}
The Jarvis March algorithm works by first finding the element with the minimum x coordinate, since it is guarenteed to be on the convex hull. In an infinite loop, we select a random point, q, trying to find the next point on the convex hull. Then, iterate over the set of points, comparing the random point selected (q), the previous point that was found on the convex hull (p) and every other point within the set of points. During each iteration, update q is the most clockwise point. This will set q to the next greatest clockwise point from any other point in the set. We set p to the new found point on the hull, update the list of convex points, and repeat until we find the original leftmost point again.

\subsubsection*{Efficiency}

\underline{Add something about output-sensitivity of Jarvis March}

The best-case efficiency is TODO \underline{This follows output-sensitivity, and is $O(n)$, which you cover somewhere else}

The worst-case complexity is $O(n^2)$-time, which occurs when all the points are on the hull. This is because in order to find the element on the convex hull, the points on the hull must be compared to every other element, which turns $O(nh)$ into $O(n^{2})$, when $n = h$.

\subsubsection*{Citation}

ADD CITATION
